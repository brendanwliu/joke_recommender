{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../joke_recommender/data/'\n",
    "df = pd.read_csv(input_path + 'joke_dataframe.csv').drop(['Unnamed: 0', 'JokeId'], axis = 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>User1</td>\n",
       "      <td>5.10</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>5.15</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.76</td>\n",
       "      <td>3.30</td>\n",
       "      <td>-2.57</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>...</td>\n",
       "      <td>5.34</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>3.59</td>\n",
       "      <td>7.18</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6.31</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User2</td>\n",
       "      <td>-8.79</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>1.99</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>5.39</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-8.69</td>\n",
       "      <td>-4.66</td>\n",
       "      <td>...</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2.86</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>4.13</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User3</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-2.91</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>7.52</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-8.40</td>\n",
       "      <td>4.37</td>\n",
       "      <td>...</td>\n",
       "      <td>1.84</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>1.65</td>\n",
       "      <td>-3.79</td>\n",
       "      <td>3.98</td>\n",
       "      <td>-6.46</td>\n",
       "      <td>-6.89</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User4</td>\n",
       "      <td>7.14</td>\n",
       "      <td>-3.88</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.26</td>\n",
       "      <td>6.65</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>7.28</td>\n",
       "      <td>-5.15</td>\n",
       "      <td>-7.14</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.47</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4.71</td>\n",
       "      <td>-5.19</td>\n",
       "      <td>6.26</td>\n",
       "      <td>3.93</td>\n",
       "      <td>-2.57</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User5</td>\n",
       "      <td>-8.79</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>8.98</td>\n",
       "      <td>7.67</td>\n",
       "      <td>8.25</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.52</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>2.48</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>9.37</td>\n",
       "      <td>8.30</td>\n",
       "      <td>9.13</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>9.13</td>\n",
       "      <td>9.17</td>\n",
       "      <td>9.17</td>\n",
       "      <td>9.08</td>\n",
       "      <td>8.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User73417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.64</td>\n",
       "      <td>-7.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User73418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>8.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User73419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User73420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.29</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>User73421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73422 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1     2     3     4     5     6     7     8     9   ...  \\\n",
       "User1      5.10  4.90  1.75 -4.17  5.15  1.75  4.76  3.30 -2.57 -1.41  ...   \n",
       "User2     -8.79 -0.87  1.99 -4.61  5.39 -0.78  1.60  1.07 -8.69 -4.66  ...   \n",
       "User3     -3.50 -2.91 -2.18 -0.10  7.52  1.26 -5.39  1.50 -8.40  4.37  ...   \n",
       "User4      7.14 -3.88 -3.06  0.05  6.26  6.65 -7.52  7.28 -5.15 -7.14  ...   \n",
       "User5     -8.79 -0.58 -0.58  8.98  7.67  8.25  4.08  2.52 -9.66  2.48  ...   \n",
       "...         ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "User73417   NaN   NaN   NaN   NaN -0.63   NaN -3.64 -7.23   NaN   NaN  ...   \n",
       "User73418   NaN   NaN   NaN   NaN  9.51   NaN -4.95  8.59   NaN   NaN  ...   \n",
       "User73419   NaN   NaN   NaN   NaN -7.67   NaN   NaN -8.79   NaN   NaN  ...   \n",
       "User73420   NaN   NaN   NaN   NaN -1.60   NaN -5.29 -3.69   NaN   NaN  ...   \n",
       "User73421   NaN   NaN   NaN   NaN  8.30   NaN -1.36  0.29   NaN   NaN  ...   \n",
       "\n",
       "             90    91    92    93    94    95    96    97    98    99  \n",
       "User1      5.34 -4.61  3.59  7.18  0.92  6.31 -4.95 -0.19  3.25  4.37  \n",
       "User2      3.59  1.21  2.86 -0.05 -1.75 -1.02 -0.97  4.13 -1.84  2.96  \n",
       "User3      1.84 -4.03 -1.41  1.65 -3.79  3.98 -6.46 -6.89 -2.33 -7.38  \n",
       "User4     -4.47  6.36  4.71 -5.19  6.26  3.93 -2.57  1.07  2.33 -0.34  \n",
       "User5     -0.29  9.37  8.30  9.13 -3.45  9.13  9.17  9.17  9.08  8.98  \n",
       "...         ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "User73417  0.44   NaN   NaN   NaN   NaN   NaN  0.78   NaN   NaN   NaN  \n",
       "User73418   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "User73419 -1.99   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "User73420   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "User73421   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[73422 rows x 100 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = model_selection.train_test_split(df, test_size=0.25, random_state=42)\n",
    "# Converting the data into Torch tensors\n",
    "training_set = torch.FloatTensor(np.array(df_train))\n",
    "test_set = torch.FloatTensor(np.array(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "train, test = training_set.to(device), test_set.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_users, n_items, layers=[16, 8], dropout=False):\n",
    "        super().__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=100, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (fc4): Linear(in_features=20, out_features=100, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(net.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        ...,\n",
       "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "        [ 0.6372,  0.4647, -0.3103,  ..., -0.0185, -0.0830,  0.0138],\n",
       "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
